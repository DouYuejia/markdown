# **Audited Auctions: Addressing Externalities in One-sided Mechanisms**

## Paper summary11:

The paper entitled "Audited Auctions: Addressing Externalities in One-sided Mechanisms" investigates the use of auction mechanisms with audits to resolve externality issues in one-sided auction scenarios, where bidders exhibit preferences over mechanism outcomes beyond their private valuations (i.e., externalities). The authors first highlight the shortcomings of traditional approaches to handling externalities in auctions, such as the use of dummy bids, and propose an enhanced auction model wherein the auctioneer may audit bidders to learn their externalities and impose corresponding penalties. The optimization objective of this paper is to maximize the sum of individual values and externalities, which is a new definition of social welfare for audited auction settings. 

The authors systematically formalizes core concepts in the audited auction scenario, including auction configurations, bidder incentives, equilibria, and total welfare under audit mechanisms. Through several theorems and lemmas, the authors establish relationships between penalty functions and participation thresholds, and they prove that under specific settings(e.g., no competition and two discrete bidder types), the welfare-optimal participation thresholds exhibit linear characteristics. In the empirical section, the authors construct a dataset using X platform (formerly Twitter) data to simulate auction dynamics, and their experiments demonstrate that optimal participation thresholds not only enhance total welfare but also facilitate welfare redistribution from producers to users. Furthermore, they empirically validate the persistence of linear optimal thresholds in complex environments.

## Strengths and weaknesses：

**strengths**：

Combination of theoretical analysis and empirical experimentation in this study ensures methodological comprehensiveness. The theoretical findings provide insights for optimizing auction mechanism design in scenarios involving bidders with externalities, while the experimental validation in the empirical section tests these theoretical propositions through simulated real-world auction.

**weaknesses**：

- Trivial conclusion and limited theoretical innovation

The conclusions of this paper is rather trivial, and the analysis lacks technical depth. The proof process implicitly assumes that the bidder's value *v* and externality *e* are mutually independent, and the platform’s auditing has zero cost,  which is not explicitly discussed in the paper. Without this key assumption, the proof process presented in the paper would not be achievable. The independence of value *v* and externality *e* along with the zero-cost auditing greatly simplifies the problem, which renders the the externality *e* effectively equivalent to a constant in the actual analysis of total welfare *w* and utility *u*, as a result, the audited auction mechanism that linearly combines *v* and *e* is essentially equivalent to traditional auction mechanisms that consider only *v*. In the theoretical analysis of the paper, the authors spend considerable effort revising the definitions of auction configurations, bidder incentives, equilibria, and total welfare in the context of audited auctions. of key results, such as the revelation principle and the optimal participation threshold, lack technical depth and theoretical value. This is primarily because the paper lacks substantial theoretical innovation compared to traditional auction mechanisms. As a result, conclusions such as the revelation principle and the construction of audited auctions using Bayesian Nash Incentive Compatible (BNIC) auctions are rather obvious, since the audited auctions are essentially equivalent to BNIC auctions. Furthermore, the authors' conclusion regarding the optimal participation threshold is straightforward to prove, requiring only basic mathematical knowledge. The above perspective indicates that the introduction of the externality concept lacks theoretical value, and the conclusions do not hold significant reference value and theoretical innovation. 

- Inadequate experimentation

This paper does not strictly align with the definition of the "Empirical and Experiment" track, primarily due to its non-rigorous data synthesis methods and the use of a limited and biased dataset. In the experimental section, the authors subjectively annotated key data features but failed to provide consistency checks to demonstrate the objectivity and fairness of the annotation process. When constructing the dataset, the authors only used platform data with more than 400 ratings, which undoubtedly introduced significant sample bias, and the dataset size is notably limited. The construction of externality data primarily relies on note authors' value ratings of the current post, which inevitably creates a correlation between the externality data and the item's value. This contradicts the paper's key assumptions and undermines the credibility of the experimental results.

- Unclear notation and definition

In addition to the aforementioned issues, we note that the notation in this paper is used in an unclear manner, lacking mathematical rigor, and there are inconsistencies in variable definitions (e.g., the utility of bidders). For some critical definitions and metrics, the authors fail to provide clear explanations upon their first introduction (e.g., the "counterfactual auction" in Table 2). Furthermore, the result figures (such as Fig. 1) are presented in a way that makes them difficult to interpret quickly.

## Comments for authors：

We believe that instead of deriving results nearly identical to those without considering externalities, it would be more valuable to relax the strong assumption of mutual independence between externality *e* and value *v*. Exploring more general scenarios with complex relationships between these variables and their impact on optimal auction mechanisms would significantly enhance the study, and the conclusion should be re-evaluated accordingly. For the empirical experiment section, we recommend that the authors carefully refer to the definition of this track and address the aforementioned shortcomings, particularly by adopting more reasonable data construction methods and enriching the experimental content. Additionally, we suggest that the authors thoroughly review the notation system, resolve inconsistencies in variable definitions, and provide clear explanations for all symbols and variables upon their first introduction.

## Questions for author response：

-  How would relaxing the assumptions  mutual independence between externality *e* and value *v* change the results?
- In what specific real-world scenarios do the current assumptions of mutual independence between *e* and *v* hold? If they are not common in practice, why did you choose such assumptions?
- Regarding the issue of sample bias in the experimental data, how would the effectiveness of audited auctions change if an unbiased dataset were properly constructed? 
- We note that the paper assumes platform audits are costless, which clearly does not align with reality. If audit costs are taken into consideration, how would the proposed method need to be modified, and would it still work effectively?

## Comments for PC：

This paper focuses on designing auction mechanisms with externalities, which is a valuable research topic. However, it suffers from several significant drawbacks, primarily reflected in the overly simplified model assumptions, trivial conclusions, and insufficient theoretical innovation. Additionally, the unreasonable dataset construction methods, inadequate experimental results, and unclear use of symbols and variables further diminish the quality of the paper. Given these notable deficiencies, we recommend that the authors make substantial revisions based on the previously mentioned shortcomings to enhance the quality of the paper. If the authors can address these issues, the paper may have potential for acceptance. However, in its current state, we believe the quality of the paper falls significantly short of the standards required for acceptance.

## Overall merit：1

## Reviewer expertise：4