## 1.请问预训练大模型相对于传统的深度学习模型有哪些优势？预训练大模型起作用的关键因素是什么？预训练大模型是否就是人工智能的终极形式？

大模型有两个关键优势，一个是大，一个是预训练。这里的大，指的是模型的参数很大，也相应说明需要大量的数据才能将它训练好，对于如此多的数据我们必然不可能对其进行标注，而是使用自监督的方式将它训练起来。因为大模型的参数量大，所以根据scaling law，模型的能力上限很高，体现在泛化能力很强。

至少目前，大模型已经体现很强的能力，已经有点像AGI了，但毕竟还是没有达到AGI。最终的形式目前还是不确定的，根据自己的认知谈，言之有理即可。是：能力很强；不是：幻觉、推理过程不保证正确、黑盒：缺乏很强的计算逻辑性与校验性。

## 2.自监督学习为什么能在人工智能领域大放异彩？自监督学习主要分为哪两大类方法？自监督学习是否还有改进空间，或者是否还有其他范式？

自监督学习通过赋予模型在大量未标注数据上训练的能力，解决了大参数模型训练的问题。

基于代理任务的；基于对比学习的；

其他范式：基于mask，基于重构，基于增强的⽅式

言之有理即可。自监督学习的缺点，需要加入上下文，加入负反馈

 

## 3.基于代理任务的自监督学习方法最容易出现的问题是什么？结合自身研究领域的具体例子，谈谈如何避免出现这个问题导致性能下降?

最大的缺点：设定的代理任务有可能有问题，导致模型走捷径完成了代理任务，但实际上模型并没有学到本质的知识。有问题：算法？训练数据？导致模型走捷径。

例如数据中可能有跟任务相关的信息，例如，在⾃然语⾔处理（NLP）领域，如果我们设计⼀个代理任务来预测⽂本中的下⼀个单词，⽽所⽤的数据集是⾼度重复且简单的句⼦，模型可能仅仅记住了这些句⼦的模式，⽽未能理解上下⽂或词汇的真正含义。这样，虽然模型在训练集上的表现很好，但在⾯对复杂的真实数据时，其表现可能会显著下降。

## 4.对比学习的负样本为什么非常重要？SimCLR能够起作用的关键tricks是什么？MoCo是如何降低对大batchsize的依赖的？

对比学习需要将正样本拉近，将负样本拉远。负样本之所以重要，是因为其影响距离；

simclr为了构建自监督，用了多种增强的方式复杂组合在一起，增大样本差别，加大了学习难度，让学到的表示更强；使用embedding网络得到表示后，并没有在表示上直接做对比，而是映射完再做对比。此外，对于下游任务中的如类别、纹理、颜色等信息，我们需要降低对这些信息的过拟合来学习更多的泛化性知识。

对比学习中，batch中负样本越多，效果越好；MOCO中把所有的其他样本当作负样本，这样负样本的数目实际上就是由batchsize决定的，batchsize越大，负样本越多。但是batchsize越大，意味着显存消耗越大，为了解决这个问题，用memory（momenta？）的机制把历史的模型记下来，把历史的负样本存在一个动态更新的memory队列中，因此大部分负样本都是从memory中取出的，就不需要那么大的batchsize了。memory本身是没有梯度的，因此对训练的开销上没有过多的增加，提高了训练效率。此外，还需要将历史的模型与当前的模型融合，从而更新参数，使其包含现有模型的成分，然后就可以把memory中的embedding也更新一遍。

## 5.迁移学习为什么在机器学习领域具有非常重要的地位？多任务学习、领域迁移、元学习、连续学习与迁移学习有何本质的联系？这些分析对我们今后的研究工作有什么重要启发？

传统的机器学习是独立同分布的假设，但真实的环境有可能是ood（out of distribution）。所以传统的机器学习即使训练的再好，在实际使用时效果也可能不好。所以迁移学习的重要性就是因为它能解决日常生活中真实存在的ood假设下训练的问题。

本质的联系：这四种可以都认为是某种特定形式的迁移学习。多任务学习：多个任务放在一起学习，希望多任务之间是可以互相关联的，知识是可以共享的，起到正向迁移的作用；领域迁移：通常认为是两个任务（domain）之间的迁移，每个domain上定义的任务是一样的，比如分类的标签系统都是一样的，只是说数据的形式、分布有区别。也就是训练同一个分类器，将知识从一个domain迁移到另一个domain。元学习：元学习和多任务学习的区别在于目标不一样，多任务学习希望在所有训练的任务上表现好，而元学习在许多任务上训练完以后，希望在新的没见过的任务上的迁移能力好。连续学习：连续学习假定任务是一个一个来的，假定训练上并不能回看，要求和多任务学习一样，希望在所有任务上表现好。

iid不常见，ood才常见，当前我们的很多研究其实是按照iid假设来做的，但是本质上是有ood的，所以如果觉得创新度不够，可以考虑将迁移学习的算法引用到自己的工作中，贴近现实情况。 

## 6.领域迁移和领域泛化有什么区别和联系？请各通过一个经典算法来阐述其核心思想。

区别：可用的数据设定不一样，领域迁移的数据通常是见过的，领域泛化的数据通常是没见过的，从这个角度领域泛化更困难。

迁移算法：

泛化算法：

## 7.迁移学习的理论分析难点到底在哪里？有哪些技巧去克服这些难点？

迁移学习最核心的就是ood假设，其理论分析难点也来自于ood。具体来讲，就是通常就是分析泛化误差界，其实就是期望误差减去经验误差。对迁移学习而言，期望误差是在目标域上的，但是目标域上没有数据。计算误差是需要标签的，但是我们假定所有数据都是无标签的，因此没有办法计算期望误差。但是在source域上可以计算经验误差，因此我们真实要约束的是target域上的期望误差，我们的方法是通过度量两个领域的差异，将目标域的期望误差转换成source域的经验误差加上两个域之间的gap。

## 8.传统的小样本学习有哪几大类方法？请每一类方法列出一个经典算法，在预训练大模型出现后，比较实用的小样本学习方法是什么？这一类小样本学习方法有哪几大类别？

基于模型的、基于黑盒的；基于梯度、基于优化的（MAML）；基于测度的、基于非参数的方式（protonet）

小样本微调，参数高效的微调，分为三大类：把参数增加一部分小样本参数，可通过prompt或者adaptor；从现有模型挑一部分参数；对参数进行参数化重构，比较有名的是lora

## 9.连续学习与在线学习和元学习的区别是什么？连续学习面临的最大挑战是什么？是否解决了这一挑战就是一个好的连续学习算法？

连续学习与元学习的区别在于：虽然都是多任务学习，连续学习的任务是一个一个来的，但是元学习的任务是一次性来的；连续学习需要在所有任务上表现好，而元学习只需要在新任务上表现好。

连续学习和在线学习很像，区别只在于假设不一样，通常连续学习是ood假设，在线学习是iid假设。



最大挑战是任务是按照顺序来的，在当前任务上训练模型而抛弃历史的任务，这就带来了历史知识的遗忘可能越来越严重，表现就是在当前任务上表现总是最好的，在历史任务上表现越来越差。

连续学习有两个目标：尽可能少遗忘，同时希望在所有见过的任务上表现好，这样来看解决遗忘是最低的要求，这并不意味着可以在所有任务上综合表现都好。

## 10.扩散模型相对其他两种生成模型（GAN和Autoregressive）具有哪些优势？扩散模型还有哪些缺点？如何通过改进模型来规避这些缺点？

扩散模型的优势：生成质量好、生成多样性强、推理速度快。

缺点：因为要进行去噪过程，其中需要很多步才可以完成，相对GAN和基于transformer的模型要慢一点。







